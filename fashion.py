# -*- coding: utf-8 -*-
"""fashion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gfda7LmJaeSGh2RCpjf9Of8mMaeWijy4

Upload the fashion_train.csv file to your google drive and specify the correct path in the main method. When prompted, provide the authorization key.
"""

# Machine Learning Homework 4 - Image Classification

__author__ = 'Nijat Khanbabayev. nk6ce'

# General imports
import numpy as np
import matplotlib.pyplot as plt
from sklearn.utils import shuffle
from sklearn import metrics
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn import preprocessing
import os
import sys
import pandas as pd

# Keras
import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten
from keras.backend import sigmoid
from keras.utils.generic_utils import get_custom_objects
from keras.layers import Activation
from keras.wrappers.scikit_learn import KerasClassifier

# Google Colab stuff
from google.colab import drive
drive.mount('/content/drive', force_remount = True)

"""The below methods have been provided for you."""

### Already implemented
def get_data(datafile):
    dataframe = pd.read_csv(datafile)
    data = list(dataframe.values)
    labels, images = [], []
    for line in data:
        labels.append(line[0])
        images.append(line[1:])
    labels = np.array(labels)
    images = np.array(images).astype('float32')
    images /= 255
    return images, labels

def swish(x, beta = 1):
    return (x * sigmoid(beta * x))
get_custom_objects().update({'swish': Activation(swish)})

### Already implemented
def visualize_weights(trained_model, num_to_display=10, save=True, hot=True):
    layer1 = trained_model.layers[0]
    weights = layer1.get_weights()[0]

    # Feel free to change the color scheme
    colors = 'hot' if hot else 'binary'
    try:
        os.mkdir('weight_visualizations')
    except FileExistsError:
        pass
    for i in range(num_to_display):
        wi = weights[:,i].reshape(28, 28)
        plt.imshow(wi, cmap=colors, interpolation='nearest')
        if save:
            plt.savefig('./weight_visualizations/unit' + str(i) + '_weights.png')
        else:
            plt.show()


### Already implemented
def output_predictions(predictions, model_type):
    if model_type == 'CNN':
        with open('CNNpredictions.txt', 'w+') as f:
            for pred in predictions:
                guj = np.argmax(pred)
                f.write(str(guj) + '\n')
    if model_type == 'MLP':
        with open('MLPpredictions.txt', 'w+') as f:
            for pred in predictions:
                f.write(str(pred) + '\n')

"""Implement the following method to generate plots of the train and validation accuracy and loss vs epochs. 
You should call this method for your best-performing MLP model and best-performing CNN model 
(4 plots total--2 accuracy plots, 2 loss plots).
"""

def plot_history(history):
    train_loss_history = history.history['loss']
    val_loss_history = history.history['val_loss']

    train_acc_history = history.history['accuracy']
    val_acc_history = history.history['val_accuracy']

    # plot
    plt.plot(train_loss_history)
    plt.plot(val_loss_history)
    plt.title('training loss and validation loss vs epoch number')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['train', 'test'], loc='best')
    plt.show()
    plt.plot(train_acc_history)
    plt.plot(val_acc_history)
    plt.title('training accuracy and validation accuracy vs epoch number')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['train', 'test'], loc='best')
    plt.show()

"""Code for defining and training your MLP models"""

def create_mlp(args=None):
 #set num_classes to 784
	model = Sequential()
	model.add(Dense(250, activation = 'sigmoid', input_dim= 28*28))
	model.add(Dense(100, activation= "sigmoid"))
	model.add(Dense(10, activation= "relu"))

    # Define Optimizer
	# if args['opt'] == 'sgd':
	# 	optimizer = 'sgd'
	# elif args['opt'] == 'adam':
	#     optimizer = keras.optimizers.Adam(...)

    # Compile
	model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.SGD(learning_rate= 0.02), metrics=['accuracy'])

	return model

def train_mlp(x_train, y_train, x_vali=None, y_vali=None, args=None):
    # You can use args to pass parameter values to this method
    y_train = keras.utils.to_categorical(y_train, num_classes= 10)
	# I commented out y_train
    model = create_mlp(args)
    history = model.fit(x_train, y_train, epochs = 15, batch_size = 30, validation_split = 0.1, shuffle = True)
    return model, history

"""Code for defining and training your CNN models"""

def create_cnn(args=None):
    # You can use args to pass parameter values to this method

    # 28x28 images with 1 color channel
	input_shape	=	(28,	28,	1)	
	model	=	keras.Sequential(	
	[	
		keras.Input(shape=input_shape),	
		keras.layers.Conv2D(128,	kernel_size=(4,	4), padding= 'same', activation ="relu"),
		keras.layers.MaxPooling2D(pool_size=(2,	2)),
		keras.layers.GaussianDropout(rate = 0.12),
		keras.layers.Conv2D(64,	kernel_size=(3,	3), padding= 'same', dilation_rate=2, activation ="relu"),
		keras.layers.MaxPooling2D(pool_size=(2,	2)),
		keras.layers.Flatten(),
		# keras.layers.Dense(100, activation= "softmax"),		
		keras.layers.Dense(10, activation= "softmax")	
	]
	)

    # Optimizer
	# if args['opt'] == 'sgd':
	# 	optimizer = keras.optimizers.SGD(lr=args['learning_rate'])
	# elif args['opt'] == 'adam':
	# 	optimizer = keras.optimizers.Adam(lr=args['learning_rate'])


#below is good, 0.87 on validation set
	# input_shape	=	(28,	28,	1)	
	# model	=	keras.Sequential(	
	# [	
	# 	keras.Input(shape=input_shape),	
	# 	keras.layers.Conv2D(64,	kernel_size=(3,	3),	activation ="relu"),
	# 	keras.layers.MaxPooling2D(pool_size=(2,	2)),	
	# 	keras.layers.Conv2D(32,	kernel_size=(3,	3),	activation ="relu"),	
	# 	keras.layers.MaxPooling2D(pool_size=(2,	2)),	
	# 	keras.layers.Flatten(),		
	# 	keras.layers.Dense(10, activation="softmax"),	
	# ]
	# )
	#I thinj learning rate was 0.0175

    # Compile

	model.compile(loss = keras.losses.CategoricalCrossentropy(),optimizer = keras.optimizers.Adam(learning_rate=0.0008),
	              metrics=['accuracy'])

	return model



def train_cnn(x_train, y_train, x_vali=None, y_vali=None, args=None):
	# You can use args to pass parameter values to this method
	x_train = x_train.reshape(-1, 28, 28, 1)
	y_train = keras.utils.to_categorical(y_train, num_classes= 10)
	model = create_cnn(args)
	history = model.fit(x_train, y_train, epochs = 7, batch_size = 25, shuffle = True)
 
 #add back  in: validation_split = 0.1 if want to do more
 #batch_size = 20
	return model, history

"""An optional method you can use to repeatedly call create_mlp, train_mlp, create_cnn, or train_cnn. 
You can use it for performing cross validation or parameter searching.

Main method. Make sure the file paths here point to the correct place in your google drive.
"""

if __name__ == '__main__':
  ### Switch to "grading_mode = True" before you submit ###
  grading_mode = True
  if grading_mode:
        # When we grade, we'll provide the file names as command-line arguments
    if (len(sys.argv) != 3):
        print("Usage:\n\tpython3 fashion.py train_file test_file")
        exit()
    train_file, test_file = sys.argv[1], sys.argv[2]
    # train_file = '/content/drive/My Drive/fashion_data2student/fashion_train.csv'
    # test_file = '/content/drive/My Drive/fashion_data2student/fashion_test.csv'
    x_train, y_train = get_data(train_file)
    # #history1_ is my name
    
    x_test, y_test = get_data(test_file)


    
    x_test = x_test.reshape(-1, 28, 28, 1)
    cnn_model, cnn_history = train_cnn(x_train,y_train)
    cnn_predictions = cnn_model.predict(x_test)
    cnn_predictions = output_predictions(cnn_predictions, model_type='CNN')

  # Include all of the required figures in your report. Don't generate them here.
  else:
    ### Edit the following two lines if your paths are different
    train_file = '/content/drive/My Drive/fashion_data2student/fashion_train.csv'
    test_file = '/content/drive/My Drive/fashion_data2student/fashion_test.csv'
    # MLP
    # mlp_model, mlp_history = train_and_select_model(train_file, model_type='MLP', grading_mode=False)
    x_train, y_train = get_data(train_file)

    x_test, y_fake = get_data(test_file)
    # mlp_model, mlp_history = train_mlp(x_train, y_train)
    # plot_history(mlp_history)
    # visualize_weights(mlp_model, num_to_display= 10)
    # visualize_weights(mlp_model, num_to_display= 4)
    # print(mlp_model.summary())

    # CNN
    # cnn_model, cnn_history = train_and_select_model(train_file, model_type='CNN', grading_mode=False)


    cnn_model, cnn_history = train_cnn(x_train,y_train)


    plot_history(cnn_history)
    print(cnn_model.summary())

    # x_train1 = x_train[int(len(x_train)*0.1):]
    # y_train1 = y_train[int(len(y_train)*0.1):]

    # x_val = x_train[:int(len(x_train)*0.1)]
    # y_val = y_train[:int(len(y_train)*0.1)]

    x_train1,x_val,y_train1,y_val = train_test_split(x_train,y_train,test_size=.1,random_state=1)

    user_train = zip(x_train1, y_train1)
    user_val = zip(x_val, y_val)


    # hyp_params = {'learn' : 0.0005,
    #               'epochs' : 7,
    #               'train_fp' : x_train1,
    #               'test_fp' : y_train1,
    #               'components' : 784
    #             }
    # x_train1 = pca(x_train1,components=hyp_params['components'])
    # model, history = log_reg(x_train1, y_train1, args=hyp_params)


    # pca_1 = PCA(n_components = 784)
    # scaler = StandardScaler()
    # scaler.fit(x_train1)
    # x_train_a = scaler.transform(x_train1)
    # pca_1.fit(x_train_a)
    # x_train_pca=pca_1.fit_transform(x_train_a)
    # model, history = log_reg(x_train_pca, y_train1, args=hyp_params)

def pca(x_train, components=150):
  scaler = StandardScaler()
  scaler.fit(x_train)
  x_sc_train = scaler.transform(x_train)
  pca = PCA(n_components=components)
  pca.fit(x_sc_train)
  x_train_pca=pca.fit_transform(x_train)
  plt.plot(np.cumsum(pca.explained_variance_ratio_))
  plt.xlabel('Number of components')
  plt.ylabel('Cumulative explained variance')
  plt.show()
  return x_train_pca

def log_reg(x_train, y_train, args=None):
    # Define model architecture
    model = keras.Sequential([
                                keras.layers.Input(shape=(args['components'])),
                                keras.layers.Dense(10, activation= "softmax")	
                                ])

    # Compilation
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=args['learn']),
              	loss='categorical_crossentropy',
              	metrics=['accuracy'])

    #Training
    history = model.fit(x=x_train,
                        y=y_train,
                        epochs=args['epochs'],
                        validation_split=0.1)
    return model, history

from google.colab import drive
drive.mount('/content/drive')